"""
Visual Flow Diagrams: Generative TRM の入出力と処理フロー

このファイルは、テキストベースで処理フローを可視化したものです。
"""

# ============================================================================
# DIAGRAM 1: 迷路版TRM vs 言語版TRMの比較
# ============================================================================

"""
┌─────────────────────────────────────────────────────────────────────────────┐
│                    元々のTRM（迷路解法版）                                    │
└─────────────────────────────────────────────────────────────────────────────┘

    迷路 [3x3]:          トークン化:           埋め込み:
    ┌─┬─┬─┐            [0 1 2]              x: [B=1, L=9, D=256]
    │ │ │ │            [3 4 5]             ┌──────────────────┐
    ├─┼─┼─┤     →      [6 7 8]      →      │v0│v1│v2│v3│...│v8│
    │ │ │ │                                └──────────────────┘
    ├─┼─┼─┤            初期化:
    │ │ │ │            y = x              再帰処理（n=2, T=2, N=2）
    └─┴─┴─┘            z = 0              for _ in range(2):
                                                z = net(x,y,z)
                                                y = net(y,z)
                                           
                                           出力:
                                           logits: [B=1, L=9, vocab=2]
                                           ┌──────────────────┐
                                           │通│通│壁│通│....│通│
                                           └──────────────────┘
                                           
                                           元の迷路に戻す:
                                           ┌─┬─┬─┐
                                           │通│通│壁│
                                           ├─┼─┼─┤
                                           │通│...│通│
                                           └─┴─┴─┘


┌─────────────────────────────────────────────────────────────────────────────┐
│                    言語版TRM（Next Token Prediction版）                      │
└─────────────────────────────────────────────────────────────────────────────┘

    文章:              トークン化:            埋め込み:
    「私は学生です」   [235 67 432 189]      x: [B=1, L=4, D=256]
                                             ┌──────────────────┐
                                             │e0│e1│e2│e3│      │
                                             └──────────────────┘
                                             
                                             初期化:
                                             y = x
                                             z = 0
                                             
                                             再帰処理（同じ構造）
                                             for sup in range(2):
                                                 z = net(x,y,z)
                                                 y = net(y,z)
                                             
                                             出力:
                                             logits: [B=1, L=4, vocab=16000]
                                             ┌────────────────────────────┐
                                             │p₀[0..15999]│p₁│p₂│p₃│      │
                                             └────────────────────────────┘
                                             
                                             各位置の確率分布:
                                             p₀ = P(次トークン | "私")
                                             p₁ = P(次トークン | "私は")
                                             p₂ = P(次トークン | "私は学生")
                                             p₃ = P(次トークン | "私は学生です")
"""

# ============================================================================
# DIAGRAM 2: 訓練時の詳細フロー
# ============================================================================

"""
┌─────────────────────────────────────────────────────────────────────────────┐
│                        訓練時のフロー（forward()）                            │
└─────────────────────────────────────────────────────────────────────────────┘

[Input]
┌────────────────────────────────────┐
│ input_ids:   [235, 67, 432, 189]   │
│ target_ids:  [67, 432, 189, EOS]   │  ← 次トークンのラベル
│ attn_mask:   [1, 1, 1, 1]          │
└────────────────────────────────────┘
                  ↓
[Embedding + Positional Encoding]
┌────────────────────────────────────┐
│ x = [B=1, L=4, D=256]              │ ← 変わらない
└────────────────────────────────────┘
                  ↓
[Initialize States]
┌────────────────────────────────────┐
│ y = x.clone()    [1, 4, 256]       │
│ z = zeros_like(x) [1, 4, 256]      │
└────────────────────────────────────┘
                  ↓
[Deep Supervision Loop] supervision_steps=2
                  ↓
    ┌─────────────────────────────────────────┐
    │ Supervision Step 1                      │
    │                                         │
    │ [Deep Recursion] (deep_steps=2)         │
    │   └─ no_grad loop × 1                   │
    │   └─ grad loop × 1                      │
    │   │   for latent_step in [1,2]:         │
    │   │     z = forward_xyz(x,y,z) [1,4,256]│
    │   │     y = forward_yz(y,z) [1,4,256]   │
    │   │                                     │
    │   └─ y_grad, y_detached ← 保存          │
    │                                         │
    │ [Output Head]                           │
    │   logits = output_head(y_grad)          │
    │   shape: [1, 4, 16000]                  │
    │                                         │
    │   logits[:, 0, :] 対 target_ids[0]=67   │
    │   logits[:, 1, :] 対 target_ids[1]=432  │
    │   logits[:, 2, :] 対 target_ids[2]=189  │
    │   logits[:, 3, :] 対 target_ids[3]=EOS  │
    │                                         │
    │ [Loss Computation]                      │
    │   ce_loss = CrossEntropy(logits, targets)│
    │   act_labels = compute_correctness()    │
    │   act_loss = BCE(q_hat, act_labels)     │
    │   total_loss = ce_loss + act_loss       │
    │                                         │
    │ [Detach for Next Step]                  │
    │   y = y_detached  ← 勾配を切る           │
    │   z = z_detached                        │
    └─────────────────────────────────────────┘
                  ↓
    ┌─────────────────────────────────────────┐
    │ Supervision Step 2                      │ ← 同じプロセス
    │ (入力 x は常に同じ)                      │
    └─────────────────────────────────────────┘
                  ↓
[Loss Aggregation]
┌──────────────────────────────────────────────┐
│ mean_ce_loss = avg(ce_loss_1, ce_loss_2)     │
│ mean_act_loss = avg(act_loss_1, act_loss_2)  │
│ final_loss = mean_ce_loss + w * mean_act_loss│
└──────────────────────────────────────────────┘
                  ↓
[Backward + Optimize]
"""

# ============================================================================
# DIAGRAM 3: 生成時のフロー
# ============================================================================

"""
┌─────────────────────────────────────────────────────────────────────────────┐
│                        生成時のフロー（generate()）                           │
└─────────────────────────────────────────────────────────────────────────────┘

[Prompt]
┌────────────────────────────────────┐
│ prompt_ids: [235, 67, 432, 189]    │
│ max_new_tokens: 10                 │
└────────────────────────────────────┘
                  ↓
[Loop: t in range(max_new_tokens)]
                  ↓
    Iteration 1:
    ├─ input_ids = [235, 67, 432, 189]  L=4
    ├─ Embedding + Pos Enc: x [1, 4, 256]
    ├─ y, z = init(x)
    ├─ Inference Cycle (no_grad)
    │   └─ y, z = latent_recursion(...) × (deep_steps × latent_steps)
    ├─ logits = output_head(y)  [1, 4, 16000]
    ├─ next_logits = logits[:, -1, :]  [1, 16000]  ← 最後の位置だけ！
    │                   ▲
    │        「位置3（最後）での推論」から
    │        「次に来るトークン」の確率分布を取得
    ├─ next_token = sample(next_logits)  e.g., 500  ← 確率に従ってサンプリング
    └─ input_ids = cat(input_ids, [500])  [235, 67, 432, 189, 500]
                  ↓
    Iteration 2:
    ├─ input_ids = [235, 67, 432, 189, 500]  L=5
    ├─ Embedding + Pos Enc: x [1, 5, 256]
    ├─ y, z = init(x)  ← 毎回リセット（重要！）
    ├─ Inference Cycle
    ├─ logits = output_head(y)  [1, 5, 16000]
    ├─ next_logits = logits[:, -1, :]  [1, 16000]  ← 位置4での推論
    ├─ next_token = sample(next_logits)  e.g., 234
    └─ input_ids = [235, 67, 432, 189, 500, 234]
                  ↓
    Iteration 3-10: (同じ)
                  ↓
[Final Output]
┌────────────────────────────────────┐
│ [235, 67, 432, 189, 500, 234, ...] │  （L=14）
└────────────────────────────────────┘


【重要なポイント】
1. 各反復で入力シーケンスが1トークン増える
2. 毎回 y, z を「リセット」している（init from x）
3. 最後の位置の logits だけを使って次トークンを決める
4. これは「自動回帰的（Auto-Regressive）」な生成です
"""

# ============================================================================
# DIAGRAM 4: y の概念図
# ============================================================================

"""
┌─────────────────────────────────────────────────────────────────────────────┐
│          y（推論状態）の意味：迷路版と言語版の対比                              │
└─────────────────────────────────────────────────────────────────────────────┘

【迷路版】
y = [B=1, L=9, D=256]

位置0（マス0）: y[0, 0, :] = このマスについての推論状態
               ↓
               「ここは通路？壁？」という判断
               初期値: ランダム、徐々に改善される

位置1（マス1）: y[0, 1, :] = マス1についての推論状態
位置2（マス2）: y[0, 2, :] = マス2についての推論状態
...
位置8（マス8）: y[0, 8, :] = マス8についての推論状態

再帰で改善: 各ステップで「隣接マスの情報」が伝播
          例: y[0, 4, :] が改善されると、
             次のステップで y[0, 3, :] や y[0, 5, :] が影響を受ける


【言語版】
y = [B=1, L=4, D=256]

位置0（トークン235="私"）: y[0, 0, :] = このトークン後の推論状態
                        ↓
                        「次は何が来そう？」への推論

位置1（トークン67="は"）: y[0, 1, :] = 「私は」までの文脈での推論状態
                        ↓
                        「私は [何か] ？」

位置2（トークン432="学生"）: y[0, 2, :] = 「私は学生」までの推論状態
                          ↓
                          「私は学生 [何か] ？」

位置3（トークン189="です"）: y[0, 3, :] = 「私は学生です」の最終推論状態
                          ↓
                          「私は学生です [何が来るか]」

再帰で改善: 各ステップで「コンテキスト全体」が見直される
          Self-Attention のおかげで、各位置が「全文脈」を反映
          例: y[0, 0, :] が改善
             → 「私」の後ろに続く文脈が明確になる
             → 次のステップで全体的な予測精度が向上


【共通構造】
位置 i での y[0, i, :] は：
- 迷路版: 「位置0-i の情報を踏まえて、位置iの予測」
- 言語版: 「位置0-i のトークンを踏まえて、次のトークンの予測」

つまり、Causal な構造です（位置i は位置i+1を見ていない）
"""

# ============================================================================
# DIAGRAM 5: Output Head のプロセス
# ============================================================================

"""
┌─────────────────────────────────────────────────────────────────────────────┐
│              Output Head: y から logits への変換                             │
└─────────────────────────────────────────────────────────────────────────────┘

訓練時:
───────────────────────────────────────────────

y (推論状態):            output_head:              logits（確率分布）:
[1, 4, 256]             Linear(D, vocab)          [1, 4, 16000]
┌─────────────────┐                             ┌─────────────────┐
│y[0,0,:]=v1  ─────→ Linear(256→16000) ───→ l[0,0,:]=16000個の値   │
│                 │                             │                 │
│y[0,1,:]=v2  ─────→                    ───→ l[0,1,:]             │
│                 │                             │                 │
│y[0,2,:]=v3  ─────→                    ───→ l[0,2,:]             │
│                 │                             │                 │
│y[0,3,:]=v4  ─────→                    ───→ l[0,3,:]             │
└─────────────────┘                             └─────────────────┘

Loss計算:
───────────────────────────────────────────────

logits                target_ids              Cross Entropy Loss
[1, 4, 16000]        [1, 4]
┌──────────────┐    ┌────────────┐             position 0:
│l[0,0,:]      │──→ │67    (正解)│  → CE(l[0,0,:], 67)
│l[0,1,:]      │──→ │432   (正解)│  → CE(l[0,1,:], 432)
│l[0,2,:]      │──→ │189   (正解)│  → CE(l[0,2,:], 189)
│l[0,3,:]      │──→ │EOS   (正解)│  → CE(l[0,3,:], EOS)
└──────────────┘    └────────────┘


生成時（推論）:
───────────────────────────────────────────────

y (推論状態):            output_head:              logits:
[1, L, 256]             Linear(D, vocab)          [1, L, 16000]
    ↓
最後の位置だけ抽出:
    ↓
logits[:, -1, :]  →  [1, 16000]

    ↓
softmax + sample:
    ↓
next_token  →  [1]  （スカラー）
"""

# ============================================================================
# DIAGRAM 6: Deep Supervision の効果
# ============================================================================

"""
┌─────────────────────────────────────────────────────────────────────────────┐
│           Deep Supervision: 複数ステップでの監督信号                          │
└─────────────────────────────────────────────────────────────────────────────┘

【Single Supervision vs Deep Supervision】

Single（一般的なLLM）:
  input_ids ─→ embedding ─→ transformer blocks × N ─→ output_head ─→ logits
                           （N個の層すべてが勾配を受け取る）
  損失: logits と target_ids で1回だけ計算


Deep Supervision（TRM）:
  input_ids ─→ embedding ─→ [再帰ステップ1]──→ output_head ─→ logits1
                                              ↓
                                           loss1を計算
                                              ↓
                          [再帰ステップ2]──→ output_head ─→ logits2
                                              ↓
                                           loss2を計算
                                              ↓
                          [再帰ステップ3]──→ output_head ─→ logits3
                                              ↓
                                           loss3を計算
  
  最終損失: (loss1 + loss2 + loss3) / 3


【TRM的な Deep Supervision の実装】

for supervision_step in range(N_supervision):
    
    # no_grad でウォームアップ
    with torch.no_grad():
        for _ in range(deep_steps - 1):
            y, z = latent_recursion(x, y, z)
    
    # 勾配ありで最後のステップ
    y, z = latent_recursion(x, y, z)
    
    # この時点での出力を評価
    logits = output_head(y)
    loss = CE(logits, targets)
    
    # 勾配を切って次のステップへ
    y = y.detach()
    z = z.detach()


【メリット】
- 浅い層でも監督信号を受け取れる（勾配消失対策）
- 再帰的に「段階的な改善」を学習できる
- メモリ効率がいい（no_grad部分は履歴がない）
"""

# ============================================================================
# DIAGRAM 7: ACT（Adaptive Computation Time）の役割
# ============================================================================

"""
┌─────────────────────────────────────────────────────────────────────────────┐
│           ACT（Binary Cross Entropy Loss）: 早期終了判定の学習                │
└─────────────────────────────────────────────────────────────────────────────┘

【概念】
「このバッチは十分に推論できたか？」を判定して、
必要なら早期に停止（記憶を節約）

フロー:
────────────────────────────────────────────

[Supervision Step i]
  ├─ y, z を再帰で更新
  ├─ logits = output_head(y)
  ├─ 推論の正確さを評価:
  │  ├─ predictions = argmax(logits, dim=-1)  [B, L]
  │  ├─ correct = (predictions == targets)    [B, L]
  │  └─ per_sequence_accuracy = all(correct per sequence)  [B]
  │
  ├─ Q-Headで「確信度」を出力:
  │  ├─ pooled = mean_pool(y)  [B, D]
  │  ├─ q_hat = sigmoid(Q_head(pooled))  [B, 1]
  │  └─ 0.0～1.0 の値（「こと推論は完了した」という確信）
  │
  ├─ ACT損失を計算:
  │  ├─ act_label = per_sequence_accuracy  [B, 1]  ← 「実際の成否」
  │  ├─ act_loss = BCE(q_hat, act_label)
  │  └─ Q-Headが「実際の正確さ」を予測するように学習
  │
  └─ Early stopping判定（推論時のみ）:
     if q_hat > threshold:
         break  ← これ以上の再帰は不要


【迷路版での例】
迷路が「ほぼ完全に解けた」なら、さらに何ステップも再帰する必要はない
→ q_hat がそれを判定して、計算を打ち切る


【言語版での例】
「このシーケンスの次のトークン予測は十分に確実」なら早期終了
→ メモリ効率向上、推論時間短縮
"""

