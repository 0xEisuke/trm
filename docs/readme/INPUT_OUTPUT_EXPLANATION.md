"""
詳細解説：Generative TRM - 入出力構造と再帰的処理フロー

このドキュメントでは、元々の「迷路・数独・ARC AGI解法用のTRM」から
「Next Token Prediction（自然言語生成）対応のGenerative TRM」への
進化における入出力構造の違いと、再帰的な処理フローを詳しく解説します。
"""

# ============================================================================
# 1. 元々のTRM（タスク学習版）の構造
# ============================================================================

"""
元々のTRM（論文 "Tiny Recursion Model"）:
- 入力：迷路や数独などの2次元配列 → 1次元トークン列に変換
  例：迷路 [3x3] → トークン列 [0,1,2,3,...,8] (9要素)
  
- 処理：
  x：入力（迷路）の埋め込み [B, 9, D] - 各マスを特徴ベクトルで表現
  y：現在の解答状態 [B, 9, D] - 各マスの「このマスは通り道？」を示す状態
  z：潜在推論状態 [B, 9, D] - 「なぜこう推論した？」という中間状態
  
  再帰処理：
    z = net(x, y, z)  # 推論の深さを増す
    y = net(y, z)     # 解答を改善
  → n回繰り返し
  → y の精度が段階的に上がる
  
- 出力：改善されたy [B, 9, D] → logits [B, 9, vocab_size]
         各マスについて「通り道か壁か」の確率分布
         
- 形式の対応：
  入力の形状（シーケンス長）と出力の形状が同じ
  → 2次元配列に戻すことで、元の問題フォーマットで直接検証可能
"""

# ============================================================================
# 2. Generative TRM（Next Token Prediction版）の構造
# ============================================================================

"""
現在のGenerative TRM:
- 入力：日本語テキスト → トークン列に変換
  例：「私は学生です」→ [235, 67, 432, 189] (トークンID)
      これは迷路のマスと同じ概念: 「各位置には1つのトークンがある」
  
- 重要な概念転換：
  【元々のTRM】では、y の各位置の出力が「該当位置の出力」でした
  【Generative TRM】でも、本質は同じです。ただし解釈が変わります：
  
  y: [B, L, D] - 各トークン位置での「推論状態ベクトル」
     各位置 i について、y[b, i, :] は「0番目から i番目までのトークンを見た
     ときの、このモデルの内部状態」を表します
  
  出力層：
    logits = output_head(y)  # [B, L, vocab_size]
    → logits[b, i, :] は「位置 i での推論状態から予測される次のトークン」の
      確率分布
    → 正確には「位置 i のトークンの予測」
"""

# ============================================================================
# 3. 入出力形状の具体例
# ============================================================================

"""
具体的な例で考えてみます：

入力シーケンス: "私は学生です"
トークン化: [私, は, 学生, です] = [235, 67, 432, 189]

【学習時】
────────────────────────────────────────────
input_ids:   [235, 67, 432, 189]  # [1, 4]
target_ids:  [67, 432, 189, EOS]  # [1, 4]
             （次のトークン予測のラベル）

処理フロー：
  1. トークン埋め込み
     token_embed(input_ids) → [1, 4, 256]
     各トークンが256次元のベクトルに変換される
  
  2. 位置埋め込みを追加
     pos_embed + token_embed → [1, 4, 256]
     x = [1, 4, 256]
  
  3. 初期化
     y = x.clone()  # [1, 4, 256] - 初期は入力と同じ
     z = 0          # [1, 4, 256] - ゼロで初期化
  
  4. 再帰処理（deep_recursion）
     for supervision_step in range(supervision_steps):  # e.g., 2回
         for deep_step in range(deep_steps):  # e.g., 2回
             for latent_step in range(latent_steps):  # e.g., 2回
                 z = tiny_net.forward_xyz(x, y, z)  # [1, 4, 256]
                 y = tiny_net.forward_yz(y, z)      # [1, 4, 256]
         
         # 出力ヘッドで確率分布を計算
         logits = output_head(y)  # [1, 4, vocab_size=16000]
         
         # Cross Entropy Loss
         loss = CE(logits, target_ids)
  
  5. 最終出力
     logits: [1, 4, 16000]
     各位置での16000個のトークンに対する確率分布

【ここが重要】
logits の形状が [1, 4, 16000] ということは：
- logits[:, 0, :] = 位置0での予測 → 「235（私）の次の予測」
- logits[:, 1, :] = 位置1での予測 → 「67（は）の次の予測」
- logits[:, 2, :] = 位置2での予測 → 「432（学生）の次の予測」
- logits[:, 3, :] = 位置3での予測 → 「189（です）の次の予測」

つまり、target_ids と完全に対応しています：
  target_ids = [67, 432, 189, EOS]
  logits[:, 0, :] の予測値 vs target_ids[0]=67
  logits[:, 1, :] の予測値 vs target_ids[1]=432
  ...

【迷路の例との対応】
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
迷路版TRM:
  x: [B, 9, D] - 迷路の各マスの初期入力
  y: [B, 9, D] - 各マスが「通路か壁か」の推論状態
  出力: [B, 9, 2] - 各マスの「通路/壁」の確率分布
  
言語版TRM:
  x: [B, L, D] - 文章の各トークン位置の入力
  y: [B, L, D] - 各位置での推論状態
  出力: [B, L, vocab_size] - 各位置での「次のトークン」の確率分布
  
→ 完全に同じ構造です！違うのは「vocab_size の大きさ」だけ。
"""

# ============================================================================
# 4. 再帰的呼び出しの本質
# ============================================================================

"""
【元々の疑問】
「確率分布を出力しているのに、それを再度入力として使う？」
「おかしくないか？」

【答え】
実は、再帰処理は「確率分布」そのものは入力していません。
入力しているのは「改善された y（推論状態）」です。

フロー図：

  入力: input_ids [235, 67, 432, 189]
  ↓
  埋め込み: x [B, 4, 256]
  ↓
  初期化: y = x, z = 0
  ↓
  ★ supervision_step #1 の deep_recursion:
    ├─ deep_step #1:
    │  └─ with torch.no_grad():  # 勾配を流さない
    │     for latent_step in [1, 2]:
    │         z = forward_xyz(x, y, z)  ← x は変わらない
    │         y = forward_yz(y, z)      ← y が改善される
    │     y_old = y.detach()  ← ここで勾配を切る！
    │
    ├─ deep_step #2:  
    │  └─ with gradient tracking:  # ★ この部分だけ勾配を記録
    │     for latent_step in [1, 2]:
    │         z = forward_xyz(x, y, z)  ← 改善されたyから出発
    │         y = forward_yz(y, z)      ← さらに改善
    │
    ├─ logits = output_head(y)  # [B, 4, 16000]
    ├─ loss = CE(logits, target_ids)
    └─ y = y.detach()  ← 次の supervision_step へ
  ↓
  ★ supervision_step #2 の deep_recursion:
    同じ処理を繰り返し
    入力は相変わらず x [B, 4, 256] - 変わらない！
    ただし y と z は「前のステップでの改善結果」から出発
  ↓
  最終出力
"""

# ============================================================================
# 5. 世界観の統一 - なぜこれは正しい設計なのか
# ============================================================================

"""
【関鍵な視点】

元々のTRM（迷路解法）:
  y が「各マスの推論状態」を持つ
  → 迷路全体を「再帰的に何度も見直す」プロセス
  → 各ステップで「ちょっとずつマスの推論が改善される」
  
言語版TRM:
  y が「各位置での推論状態」を持つ
  → 文章全体を「再帰的に何度も見直す」プロセス
  → 各ステップで「ちょっとずつ各位置の推論が改善される」

【重要な理解】
y の形状は [B, L, D]
これは「各位置 i で独立した推論状態」ではなく、
「全文脈を考慮した各位置の状態」です（Self-Attentionのおかげ）

つまり：
- 位置3での推論 (y[b, 3, :]) は、位置0-3の全コンテキストを見ています
- 位置2での推論 (y[b, 2, :]) は、位置0-2の全コンテキストを見ています
- これは Causal Attention で実装できます（ただし現在のコードにはない）

【なぜ "同じ形で入出力" が正しいのか】
迷路: 「各マスについて、このマスは通り道？」を9回推論
言語: 「各位置について、このトークンは正しい？」「次は何？」を推論

違う言い方すると：
迷路: 「この9マスの組み合わせ（迷路解）の妥当性」をスコア化
言語: 「このL個のトークン（文章）の妥当性」「続くトークン」をスコア化
"""

# ============================================================================
# 6. コード解釈 - forward() メソッド全体
# ============================================================================

"""
def forward(
    self,
    input_ids: torch.Tensor,           # [B, L] トークンID
    attention_mask: Optional[...],      # [B, L] パディング位置
    target_ids: Optional[torch.Tensor], # [B, L] 次トークンのラベル
    supervision_steps: Optional[int],
) -> Dict[str, torch.Tensor]:

  1. input_ids をトークン埋め込み + 位置埋め込み
     x = embed(input_ids)  # [B, L, D]
  
  2. 初期状態を作成
     y = x.clone()  # [B, L, D]
     z = zeros      # [B, L, D]
  
  3. Deep Supervision ループ（通常 supervision_steps=2 など）
     for sup in range(supervision_steps):  # 複数ステップ反復
         
         # Deep Recursion: 最初の T-1 回は no_grad、最後は勾配あり
         y_grad, _, y_next, z_next = self._deep_recursion_step(
             x, y, z, attention_mask
         )
         # y_grad: 勾配ありで計算された改善版
         # y_next: 勾配を切った版（次のステップの入力）
         
         # 出力層で確率分布を計算
         logits = self.output_head(y_grad)  # [B, L, vocab_size]
         
         # ACT（早期終了判定）
         pooled = self._pool_for_q(y_grad, attention_mask)
         q_hat = sigmoid(self.q_head(pooled))  # [B, 1]
         
         # 損失を計算
         if target_ids is not None:
             ce_loss = CE(logits, target_ids)  ← target と対応！
             act_labels = compute_act_labels(logits, target_ids)
             bce_loss = BCE(q_hat, act_labels)
  
  4. 複数ステップの損失を平均化
     total_loss = mean(ce_loss) + w * mean(bce_loss)

【ポイント】
- input_ids は「各ステップで常に同じ」です（x が変わらない）
- y と z は「前のステップからの改善」を引き継ぎます
- 出力（logits）は各ステップで計算されます（Deep Supervision）
"""

# ============================================================================
# 7. 生成（推論）フロー
# ============================================================================

"""
def generate(
    prompt_ids: List[int],
    max_new_tokens: int = 64,
) -> List[int]:
    
  input_ids = [235, 67, 432, 189]  # プロンプト
  
  for t in range(max_new_tokens):
      x = embed(input_ids)  # [1, L, D] ← L は増える！
      y, z = init_states(x)
      y, z, _ = inference_cycle(x, y, z)  # 推論
      
      logits = output_head(y)  # [1, L, vocab_size]
      next_token_logits = logits[:, -1, :]  # 最後の位置だけ取得！
      next_token = sample(next_token_logits)
      
      input_ids = cat([input_ids, [next_token]])  # トークン追加
  
  return input_ids

【生成で "最後の位置だけ" 取得する理由】
logits[b, L, :] = 位置L-1 における推論状態から予測される次のトークン

つまり：
logits[b, 0, :] = prompt_ids[0] の次の予測（プロンプトの一部）
logits[b, 1, :] = prompt_ids[1] の次の予測（プロンプトの一部）
...
logits[b, L-1, :] = 「入力の最後のトークン」の次の予測 ← ★ ここだけ欲しい

【迷路の例では】
全9マスについて「マス i は通路か」を同時に出力します
【言語では】
L個の位置について「次のトークンは何か」を同時に出力しますが、
生成時は最後の位置の予測だけを使って、新トークンを追加します
"""

# ============================================================================
# 8. まとめ
# ============================================================================

"""
【質問への回答】

Q: 「出力が同じ長さのトークン列だと、次のトークンの情報どこに？」

A: 出力は「トークン列」ではなく「各位置での確率分布（logits）」です
   形状: [B, L, vocab_size]
   
   各位置 i の logits[b, i, :] は「位置 i での推論」から
   「次に来るトークン」の確率分布を表しています。

Q: 「それを再帰的に呼ぶわけだから…」

A: 再帰は「logits」を呼ぶのではなく、「改善されたy（推論状態）」を
   呼び継ぎます。
   
   y は形状 [B, L, D]（埋め込みと同じ形）で、各位置での「思考状態」です。
   これは迷路版の y と同じ役割を果たしています。

Q: 「形式がおかしくないか」

A: 形式は完全に一貫しています。
   迷路版と言語版の唯一の違いは vocab_size の大きさだけです。
   - 迷路: 各マスは「通路/壁」= 2クラス
   - 言語: 各位置は「16000のトークン」= 16000クラス
   
   本質は同じです。
"""
