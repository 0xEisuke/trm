âœ… Codex ã¸ã®æŒ‡ç¤ºæ›¸ï¼ˆtrain_trm_lm.py ã«å­¦ç¿’æ›²ç·šå¯è¦–åŒ–æ©Ÿèƒ½ã‚’è¿½åŠ ã›ã‚ˆï¼‰

ä»¥ä¸‹ã®å†…å®¹ã‚’ ãã®ã¾ã¾ Codex ã«é€ã£ã¦ãã ã•ã„ã€‚

ğŸ“„ æŒ‡ç¤ºæ›¸ï¼štrain_trm_lm.py ã«å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–ï¼ˆloss/ce/actï¼‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„

I want to extend train_trm_lm.py to automatically generate training-curve plots at the end of training.

è¦æ±‚ä»•æ§˜
âœ” 1. ãƒ­ã‚°å€¤ã®è¨˜éŒ²

During training, store the following metrics after each logging step:

loss

ce_loss

act_loss

step

These values should be appended to lists, e.g.:

steps = []
losses = []
ce_losses = []
act_losses = []


Populate them at each log_every interval.

âœ” 2. å­¦ç¿’çµ‚äº†å¾Œã«æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ

After training completes (just before exiting), generate a plot using matplotlib:

æ¨ªè»¸ï¼šstep

ç¸¦è»¸ï¼šå€¤ï¼ˆloss, ce_loss, act_lossï¼‰

3æœ¬ã®æŠ˜ã‚Œç·šã‚’1æšã® figure ã«ã¾ã¨ã‚ã‚‹

å‡¡ä¾‹ã‚ã‚Š

ã‚¿ã‚¤ãƒˆãƒ«ï¼šã€ŒTraining Curvesã€

æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆæŒ‡å®šï¼ˆä¾‹ï¼šMS Gothicï¼‰

plt.rcParams["font.family"] = "MS Gothic"

âœ” 3. ãƒ—ãƒ­ãƒƒãƒˆç”»åƒã‚’ save_dir ã«ä¿å­˜

File name:

{save_dir}/training_curves.png


Use:

plt.savefig(os.path.join(args.save_dir, "training_curves.png"))


Also call:

plt.close()


at the end.

âœ” 4. å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã® import

Make sure these are added at top of train_trm_lm.py:

import matplotlib.pyplot as plt
import os

âœ” 5. æ—¢å­˜ã®å‹•ä½œã‚’å£Šã•ãªã„ã“ã¨

Training loop, checkpoint saving, evaluation, EMA updates, TRM recursion behaviorã€ã™ã¹ã¦ãã®ã¾ã¾ç¶­æŒã€‚

ãƒ­ã‚°ã®å‡ºåŠ›æ–¹æ³•ã¯å¤‰æ›´ã—ãªã„ã€‚

train loop ã«è»½è² è·ã®å‡¦ç†ã®ã¿è¿½åŠ ã™ã‚‹ã“ã¨ã€‚

ğŸ“Œ æœ€çµ‚ç›®çš„

When training finishes, the directory:

--save_dir checkpoints_spm


should contain:

step_XXXX.pt (checkpoints)

final_step_XXXX.pt

training_curves.png â† æ–°ãŸã«è¿½åŠ ã™ã‚‹ç”»åƒ

This PNG file should clearly show whether training is stable.

âœ… ä»¥ä¸Šã®ä»•æ§˜ã«åŸºã¥ã„ã¦ train_trm_lm.py ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚
å¿…è¦ãªã‚‰ã€ç§å´ã§ã€Œæœ€çµ‚çš„ãªå®Œæˆç‰ˆã‚³ãƒ¼ãƒ‰ã€ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ãã¾ã™ã€‚

Codex ãŒç”Ÿæˆã—ãŸã‚‰è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚